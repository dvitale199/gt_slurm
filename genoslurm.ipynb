{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from genoslurm.genoslurm import chunks, GenCallJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster config variables\n",
    "max_nodes = 10\n",
    "\n",
    "# paths\n",
    "userhome = '/home/dan_datatecnica_com'\n",
    "datapath = f'{userhome}/data'\n",
    "# tmp_dir = f'{userhome}/tmp'\n",
    "log_dir = f'{userhome}/logs'\n",
    "ilmn_files_path = f'{userhome}/ilmn_files'\n",
    "iaap = f'{userhome}/GenoTools/executables/iaap-cli-linux-x64-1.1.0-sha.80d7e5b3d9c1fdfc2e99b472a90652fd3848bbc7/iaap-cli/iaap-cli'\n",
    "bpm = f'{ilmn_files_path}/NeuroBooster_20042459_A2.bpm'\n",
    "egt = f'{ilmn_files_path}/recluster_09272022.egt'\n",
    "plink_file_path = f'{datapath}/gp2_plink'\n",
    "gcs_plink_path = f'gp2_uk/gp2_plink'\n",
    "gcs_idat_path = f'gp2_uk/gp2_idats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of idats in directory of choice\n",
    "# !gsutil ls gs://gp2_uk/gp2_idats/ > tmp/idats.txt\n",
    "idats_in = pd.read_csv('tmp/idats.txt', header=None)\n",
    "idat_list = idats_in.loc[1:,0]\n",
    "idat_list = [x.replace('gs://gp2_uk/gp2_idats',f'{datapath}')[:-1] for x in idat_list]\n",
    "gcs_idat_paths = [x.replace('gs://', '').rstrip('/') for x in idats_in.loc[1:,0]]\n",
    "# chunk list by max nodes\n",
    "idat_list_chunks = chunks(idat_list, max_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idat_list_chunk in enumerate(idat_list_chunks):\n",
    "\n",
    "    script_path = f'cluster_scripts/call_gts_{i}.sh'\n",
    "    job_name = f'callgts_{i}'\n",
    "    log_path = f'{userhome}/logs'\n",
    "    nodes = len(idat_list_chunk)\n",
    "    ntasks = len(idat_list_chunk)\n",
    "    time_limit = '01:00:00'\n",
    "    array = f'1-{len(idat_list_chunk)}'\n",
    "    cpus_per_task = '2'\n",
    "\n",
    "\n",
    "    job = GenCallJob(\n",
    "        sbatch_path=script_path, \n",
    "        idat_dir_ins=idat_list_chunk, \n",
    "        gcs_idat_path=gcs_idat_path, \n",
    "        iaap=iaap, \n",
    "        bpm=bpm, \n",
    "        egt=egt, \n",
    "        gcs_plink_path=gcs_plink_path,\n",
    "        log_path=log_dir,\n",
    "        job_name=job_name, \n",
    "        threads=4, \n",
    "        ntasks=ntasks, \n",
    "        cpus_per_task=3, \n",
    "        mem_per_cpu='2G', \n",
    "        time='01:00:00'\n",
    "        )\n",
    "        \n",
    "    job.write_sbatch_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/etc/profile.d/lang.sh: line 19: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory\n",
      "call_gts_0.sh                                 100% 9902    73.6KB/s   00:00    \n",
      "call_gts_1.sh                                 100% 2085    15.5KB/s   00:00    \n",
      "\n",
      "\n",
      "Updates are available for some Google Cloud CLI components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# copy scripts to vm\n",
    "!gcloud compute scp cluster_scripts/call_gts_*.sh genoslurm-uk-v1-login0:/home/dan_datatecnica_com/scripts/ --project genotools --zone europe-west2-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/etc/profile.d/lang.sh: line 19: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory\n",
      "Submitted batch job 10\n"
     ]
    }
   ],
   "source": [
    "# launch commands\n",
    "!gcloud compute ssh --zone europe-west2-a --project genotools genoslurm-uk-v1-login0 --command 'sbatch /home/dan_datatecnica_com/scripts/call_gts_1.sh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=callgts_1\n",
      "#SBATCH --ntasks=2\n",
      "#SBATCH --cpus-per-task=3\n",
      "#SBATCH --mem-per-cpu=2G\n",
      "#SBATCH --time=01:00:00\n",
      "\n",
      "\n",
      "# Processing /home/dan_datatecnica_com/data/206451070115\n",
      "mkdir -p /home/dan_datatecnica_com/data/206451070115\n",
      "gsutil cp gs://gp2_uk/gp2_idats/206451070115/* /home/dan_datatecnica_com/data/206451070115/\n",
      "/home/dan_datatecnica_com/GenoTools/executables/iaap-cli-linux-x64-1.1.0-sha.80d7e5b3d9c1fdfc2e99b472a90652fd3848bbc7/iaap-cli/iaap-cli gencall /home/dan_datatecnica_com/ilmn_files/NeuroBooster_20042459_A2.bpm /home/dan_datatecnica_com/ilmn_files/recluster_09272022.egt /home/dan_datatecnica_com/data/206451070115 -f /home/dan_datatecnica_com/data/206451070115 -p -t 4\n",
      "\n",
      "# Convert PED files to BED/BIM/FAM files using plink2\n",
      "for ped_file in /home/dan_datatecnica_com/data/206451070115/*.ped; do\n",
      "\n",
      "    cp /home/dan_datatecnica_com/data/206451070115/NeuroBooster_20042459_A2.map \"${ped_file%.*}.map\"\n",
      "    plink2 --file \"${ped_file%.*}\" --make-bed --out \"${ped_file%.*}\"\n",
      "done\n",
      "\n",
      "gsutil cp /home/dan_datatecnica_com/data/206451070115/*.{bed,bim,fam,log} gs://gp2_uk/gp2_plink/\n",
      "\n",
      " & \\\n",
      "\n",
      "# Processing /home/dan_datatecnica_com/data/206451070117\n",
      "mkdir -p /home/dan_datatecnica_com/data/206451070117\n",
      "gsutil cp gs://gp2_uk/gp2_idats/206451070117/* /home/dan_datatecnica_com/data/206451070117/\n",
      "/home/dan_datatecnica_com/GenoTools/executables/iaap-cli-linux-x64-1.1.0-sha.80d7e5b3d9c1fdfc2e99b472a90652fd3848bbc7/iaap-cli/iaap-cli gencall /home/dan_datatecnica_com/ilmn_files/NeuroBooster_20042459_A2.bpm /home/dan_datatecnica_com/ilmn_files/recluster_09272022.egt /home/dan_datatecnica_com/data/206451070117 -f /home/dan_datatecnica_com/data/206451070117 -p -t 4\n",
      "\n",
      "# Convert PED files to BED/BIM/FAM files using plink2\n",
      "for ped_file in /home/dan_datatecnica_com/data/206451070117/*.ped; do\n",
      "\n",
      "    cp /home/dan_datatecnica_com/data/206451070117/NeuroBooster_20042459_A2.map \"${ped_file%.*}.map\"\n",
      "    plink2 --file \"${ped_file%.*}\" --make-bed --out \"${ped_file%.*}\"\n",
      "done\n",
      "\n",
      "gsutil cp /home/dan_datatecnica_com/data/206451070117/*.{bed,bim,fam,log} gs://gp2_uk/gp2_plink/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat cluster_scripts/call_gts_{i}.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    outlist = []\n",
    "    for i in range(0, len(lst), n):\n",
    "        outlist.append(lst[i:i + n])\n",
    "    return outlist\n",
    "\n",
    "class GenCallJob:\n",
    "    def __init__(self, sbatch_path, idat_dir_ins, gcs_idat_path, iaap, bpm, egt, gcs_plink_path, log_path, job_name='my_job', threads=2, ntasks=1, cpus_per_task=1, mem_per_cpu='2G', time='01:00:00'):\n",
    "        self.sbatch_path = sbatch_path\n",
    "        self.idat_dir_ins = idat_dir_ins\n",
    "        # self.tmp_out_dir = tmp_out_dir\n",
    "        self.gcs_idat_path = gcs_idat_path\n",
    "        self.iaap = iaap\n",
    "        self.bpm = bpm\n",
    "        self.egt = egt\n",
    "        self.gcs_plink_path = gcs_plink_path\n",
    "        self.log_path = log_path\n",
    "        self.job_name = job_name\n",
    "        self.threads = threads\n",
    "        self.ntasks = ntasks\n",
    "        self.cpus_per_task = cpus_per_task\n",
    "        self.mem_per_cpu = mem_per_cpu\n",
    "        self.time = time\n",
    "\n",
    "    def write_header(self):\n",
    "        header = f\"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={self.job_name}\n",
    "#SBATCH --ntasks={self.ntasks}\n",
    "#SBATCH --cpus-per-task={self.cpus_per_task}\n",
    "#SBATCH --mem-per-cpu={self.mem_per_cpu}\n",
    "#SBATCH --time={self.time}\n",
    "\n",
    "\"\"\"\n",
    "        return header\n",
    "\n",
    "\n",
    "    def write_script(self, idat_dir_in, gcs_idat_path):\n",
    "        script = f\"\"\"\n",
    "# Processing {idat_dir_in}\n",
    "mkdir {idat_dir_in}\n",
    "gsutil cp gs://{gcs_idat_path}/* {idat_dir_in}/\n",
    "{self.iaap} gencall {self.bpm} {self.egt} {idat_dir_in} -f {idat_dir_in} -p -t {self.threads}\n",
    "\n",
    "# Convert PED files to BED/BIM/FAM files using plink2\n",
    "for ped_file in {idat_dir_in}/*.ped; do\n",
    "\n",
    "    cp {idat_dir_in}/NeuroBooster_20042459_A2.map \"${{ped_file%.*}}.map\"\n",
    "    plink2 --file \"${{ped_file%.*}}\" --make-bed --out \"${{ped_file%.*}}\"\n",
    "done\n",
    "\n",
    "gsutil cp {idat_dir_in}/*.{{bed,bim,fam,log}} gs://{self.gcs_plink_path}/\n",
    "\n",
    "\"\"\"\n",
    "        return script\n",
    "\n",
    "    def write_sbatch_script(self):\n",
    "        commands = []\n",
    "        header = self.write_header()\n",
    "        for idat_dir_in in self.idat_dir_ins:\n",
    "            code = idat_dir_in.split('/')[-1]\n",
    "            gcs_idat_path = f'{self.gcs_idat_path}/{code}'\n",
    "            command = self.write_script(idat_dir_in, gcs_idat_path)\n",
    "            commands.append(\n",
    "                f'\\\n",
    "srun \\\n",
    "--ntasks=1 \\\n",
    "--nodes=1 \\\n",
    "--output={self.log_path}/{self.job_name}-%j-%t.out \\\n",
    "--error={self.log_path}/{self.job_name}-%j-%t.err \\\n",
    "/bin/bash -c \"{command}\"'\n",
    "                )\n",
    "        \n",
    "        script = \" && \\\\\\n\".join(commands)\n",
    "\n",
    "        full_script = header + script\n",
    "\n",
    "        with open(f'{self.sbatch_path}', 'w') as f:\n",
    "            f.write(full_script)\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# removed stuff\n",
    "# gcsfuse --dir-mode 776 --file-mode 776 --implicit-dirs {self.gcs_idat_path} {idat_dir_in}\n",
    "# gsutil cp {idat_dir_in}/*.bed {idat_dir_in}/*.bim {idat_dir_in}/*.fam gs://{self.gcs_plink_path}/\n",
    "    # base_name=$(basename ${{ped_file}} .ped)\n",
    "     # os.system('sbatch my_sbatch_script.sh')\n",
    "                 # sbatch_script += self.write_script(idat_dir_in, gcs_idat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now loop through chunks to create a job for every {max_nodes} barcodes \n",
    "# 1 node per barcode. (n_idats<=(80*max_nodes))\n",
    "\n",
    "for i, chunk in enumerate(idat_list_chunks):\n",
    "\n",
    "    script_path = f'cluster_scripts/call_gts_{i}.sh'\n",
    "    job_name = f'callgts_{i}'\n",
    "    log_path = f'{userhome}/logs'\n",
    "    log_out = f'{log_path}/test.out'\n",
    "    log_err = f'{log_path}/test.err'\n",
    "    # log_out = f'{log_path}/{job_name}.%A_%a.out'\n",
    "    # log_err = f'{log_path}/{job_name}.%A_%a.err'\n",
    "    # ntasks = str(len(idat_list))\n",
    "    # nodes = str(len(idat_list))\n",
    "    nodes = len(chunk)\n",
    "    ntasks = len(chunk)\n",
    "    time = '01:00:00'\n",
    "    array = f'1-{len(chunk)}'\n",
    "    cpus_per_task = '1'\n",
    "\n",
    "    # Create a sbatch script\n",
    "    with open(f'cluster_scripts/call_gts_{i}.sh', 'w') as f:\n",
    "        f.write('#!/bin/bash\\n')\n",
    "        f.write(f'#SBATCH --job-name={job_name}\\n')\n",
    "        # f.write(f'#SBATCH --output={log_out}\\n')\n",
    "        # f.write(f'#SBATCH --error={log_err}\\n')\n",
    "        f.write(f'#SBATCH --ntasks={ntasks}\\n')\n",
    "        f.write(f'#SBATCH --cpus-per-task={cpus_per_task}\\n')\n",
    "        # f.write(f'#SBATCH --nodes={nodes}\\n')\n",
    "        f.write(f'#SBATCH --time={time}\\n')\n",
    "        # f.write(f'#SBATCH --array={array}\\n')\n",
    "        f.write('\\n')\n",
    "        f.write('echo \"Starting job\"\\n')\n",
    "        f.write('date\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "        for code in chunk:\n",
    "            \n",
    "            # path in vm that is mounted to bucket\n",
    "            idat_dir_in = f'{datapath}/gp2_idats/{code}'\n",
    "\n",
    "            # bucket paths\n",
    "            gcs_path = f'gp2_uk'\n",
    "            gcs_idat_path = f'{gcs_path}/gp2_idats/{code}'\n",
    "            gcs_plink_path = f'{gcs_path}/gp2_plink'\n",
    "            \n",
    "            # files not writing properly to gcs via gcsfuse so write to path in vm and copy to gcs \n",
    "            tmp_out_dir = f'{userhome}/tmp/{code}'\n",
    "            \n",
    "#             command = f'\\\n",
    "# gsutil cp -r gs://{gcs_plink_path}/ {tmp_out_dir}/; \\\n",
    "# {iaap} gencall \\\n",
    "# {bpm} \\\n",
    "# {egt} \\\n",
    "# {tmp_out_dir} \\\n",
    "# -f {tmp_out_dir} \\\n",
    "# -p \\\n",
    "# -t 2; \\\n",
    "\n",
    "\n",
    "# cp {tmp_out_dir}/NeuroBooster_20042459_A2.map \n",
    "\n",
    "# {userhome}/GenoTools/exec/plink2 \n",
    "# gsutil cp -r {tmp_out_dir}/*.{{}} gs://{gcs_plink_path}/'\n",
    "\n",
    "\n",
    "\n",
    "            command = f'\\\n",
    "mkdir {idat_dir_in}; \\\n",
    "mkdir {tmp_out_dir}; \\\n",
    "gcsfuse --dir-mode 776 --file-mode 776 --implicit-dirs {gcs_idat_path} {idat_dir_in}; \\\n",
    "{iaap} gencall \\\n",
    "{bpm} \\\n",
    "{egt} \\\n",
    "{tmp_out_dir} \\\n",
    "-f {idat_dir_in} \\\n",
    "-p \\\n",
    "-t 2; \\\n",
    "gsutil cp -r {tmp_out_dir}/ gs://{gcs_plink_path}/'\n",
    "\n",
    "            f.write(f'# Run command for file {idat_dir_in}\\n')\n",
    "            f.write(f'srun --output={log_path}/{job_name}-%j-%t.out --error={log_path}/{job_name}-%j-%t.err \"{command}\" &\\n')\n",
    "            f.write('\\n')\n",
    "\n",
    "        f.write('\\n')\n",
    "        f.write('echo \"Job finished\"\\n')\n",
    "        f.write('date\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f7160342989abd67da089259c8f7d683a0ec2850c327d5a4ff1c722e0eb3dc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
